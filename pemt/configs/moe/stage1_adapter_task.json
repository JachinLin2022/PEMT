{
    "do_test": true,
    "do_eval": true,
    "do_train": true, 
    "warmup_steps": 500,
    "save_steps": 1000,
    "save_strategy": "no",
    "model_name_or_path": "t5-base",
    "tokenizer_name": "t5-base",
    "save_total_limit": 1,
    "load_best_model_at_end": true,
    "metric_for_best_model": "average_metrics",
    "greater_is_better": true,
    "evaluation_strategy": "epoch",
    "non_linearity": "gelu_new",
    "max_source_length": 256,
    "learning_rate": 5e-4,
    "output_dir": "/mlx_devbox/users/linzhisheng.2021/ATTEMPT/attempt/result/adapter/stage1/cola",
    "per_device_train_batch_size": 128,
    "per_device_eval_batch_size": 256,
    "split_validation_test": true,
    "task_name": ["cola"],
    "eval_dataset_name": ["cola"], 
    "test_dataset_name": ["cola"], 
    "num_train_epochs": 5,
    "dataset_config_name": ["en"],
    "eval_dataset_config_name": ["en"],
    "test_dataset_config_name": ["en"],
    "predict_with_generate": true,
    "add_adapter_in_feed_forward": false,
    "add_adapter_in_feed_forward_out": true,
    "add_adapter_in_self_attention": false,
    "add_layer_norm_before_adapter": false, 
    "add_layer_norm_after_adapter": false, 
    "adapter_config_name": "adapter",
    "train_task_adapters": true,
    "task_reduction_factor": 48,
    "unfreeze_lm_head": false,
    "unfreeze_layer_norms": false,
    "overwrite_output_dir": true,
    "compute_memory": true,
    "report_to": "none",
    "add_task_embedding": true,
    "logging_steps": 10
    }